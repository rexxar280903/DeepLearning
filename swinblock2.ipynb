{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1181323,"sourceType":"datasetVersion","datasetId":671155}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c948b1c0","cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\nfrom tqdm import tqdm # Opsional, tapi sangat disarankan untuk progress bar\nfrom torch.utils.data import random_split\nfrom math import floor\n\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\nfrom tqdm import tqdm # Opsional, tapi sangat disarankan untuk progress bar\nfrom torch.utils.data import random_split\n\nimport torch.optim as optim\nimport csv\n\nimport torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.160476Z","iopub.execute_input":"2025-11-12T06:01:36.160749Z","iopub.status.idle":"2025-11-12T06:01:36.167431Z","shell.execute_reply.started":"2025-11-12T06:01:36.160729Z","shell.execute_reply":"2025-11-12T06:01:36.166467Z"}},"outputs":[],"execution_count":20},{"id":"262063d6-a8f7-4af5-95a2-7b26960e9758","cell_type":"code","source":"pip install lpips","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:20:35.997150Z","iopub.execute_input":"2025-11-12T06:20:35.997546Z","iopub.status.idle":"2025-11-12T06:22:05.947243Z","shell.execute_reply.started":"2025-11-12T06:20:35.997521Z","shell.execute_reply":"2025-11-12T06:22:05.946180Z"}},"outputs":[{"name":"stdout","text":"Collecting lpips\n  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.21.0+cu124)\nRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.26.4)\nRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.15.3)\nRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.3->lpips) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.0->lpips)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.0->lpips)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.0->lpips)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->lpips) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->lpips) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.3->lpips) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.3->lpips) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.3->lpips) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.3->lpips) (2024.2.0)\nDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":41},{"id":"0b87f4ef-1d27-40ba-bb1e-276f4588669d","cell_type":"code","source":"# !rm -rf /kaggle/working/*\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.169014Z","iopub.execute_input":"2025-11-12T06:01:36.169417Z","iopub.status.idle":"2025-11-12T06:01:36.187790Z","shell.execute_reply.started":"2025-11-12T06:01:36.169392Z","shell.execute_reply":"2025-11-12T06:01:36.186824Z"}},"outputs":[],"execution_count":21},{"id":"a9cfae7d","cell_type":"markdown","source":"## Fungsi train, custom dataset","metadata":{}},{"id":"d6b59e72","cell_type":"code","source":"import os, csv, re, time\nimport torch\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n\ndef _read_last_epoch(csv_path):\n    if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n        return 0\n    try:\n        df = pd.read_csv(csv_path)\n        if 'epoch' in df.columns and pd.api.types.is_numeric_dtype(df['epoch']):\n            df_epoch = df['epoch'].dropna()\n            return int(df_epoch.max()) if len(df_epoch) else 0\n        return 0\n    except Exception:\n        return 0\n\ndef train_model(\n    model, train_loader, val_loader, criterion, optimizer, num_epochs,\n    save_dir=\"model_checkpoints\", path=\"/kaggle/working/histor.csv\",\n    continue_global_epoch=True  # jika True, epoch global lanjutkan dari CSV\n):\n    os.makedirs(save_dir, exist_ok=True)\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n\n    history = {'train_loss': [], 'val_loss': [], 'val_psnr': [], 'val_ssim': []}\n\n    # --- run_id untuk membedakan antar run (unik) ---\n    # contoh: 2025-11-12_12-31-22\n    run_id = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n    # --- tentukan start_epoch global jika ingin melanjutkan ---\n    start_epoch_global = _read_last_epoch(path) if continue_global_epoch else 0\n\n    print(f\"Mulai Training di device: {device} | run_id={run_id} | start_epoch_global={start_epoch_global}\")\n\n    for e in range(num_epochs):\n        # epoch_in_run: 1..num_epochs (untuk nama file run ini)\n        epoch_in_run = e + 1\n        # epoch_global: lanjut dari CSV bila diminta\n        epoch_global = start_epoch_global + epoch_in_run\n\n        # ===== TRAIN =====\n        model.train()\n        running_train_loss = 0.0\n        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch_in_run}/{num_epochs} [Train]\")\n        for lr_images, hr_images in train_pbar:\n            lr_images = lr_images.to(device); hr_images = hr_images.to(device)\n            optimizer.zero_grad()\n            pred = model(lr_images)\n            loss = criterion(pred, hr_images)\n            loss.backward()\n            optimizer.step()\n            running_train_loss += loss.item() * lr_images.size(0)\n            train_pbar.set_postfix({'train_loss': loss.item()})\n        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n        history['train_loss'].append(epoch_train_loss)\n\n        # ===== VAL =====\n        model.eval()\n        running_val_loss = 0.0\n        psnr_metric.reset(); ssim_metric.reset()\n        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch_in_run}/{num_epochs} [Val]\")\n        with torch.no_grad():\n            for lr_images, hr_images in val_pbar:\n                lr_images = lr_images.to(device); hr_images = hr_images.to(device)\n                pred = model(lr_images)\n                vloss = criterion(pred, hr_images)\n                running_val_loss += vloss.item() * lr_images.size(0)\n                psnr_metric.update(pred, hr_images)\n                ssim_metric.update(pred, hr_images)\n                val_pbar.set_postfix({'val_loss': vloss.item()})\n        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n        epoch_psnr = psnr_metric.compute().item()\n        epoch_ssim = ssim_metric.compute().item()\n\n        history['val_loss'].append(epoch_val_loss)\n        history['val_psnr'].append(epoch_psnr)\n        history['val_ssim'].append(epoch_ssim)\n\n        # ===== SAVE CHECKPOINT =====\n        # nama file unik per run agar tidak pernah tabrakan\n        # contoh: model_2025-11-12_12-31-22_e1.pth\n        ckpt_name = f\"model_{run_id}_e{epoch_in_run}.pth\"\n        save_path = os.path.join(save_dir, ckpt_name)\n        torch.save(model.state_dict(), save_path)\n        print(f\"[SAVE] {save_path}\")\n\n        # ===== APPEND CSV (dengan kolom epoch terisi) =====\n        is_new = not os.path.exists(path)\n        with open(path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n            w = csv.DictWriter(\n                f,\n                fieldnames=[\"epoch\",\"epoch_in_run\",\"run_id\",\n                            \"train_loss\",\"val_loss\",\"val_psnr\",\"val_ssim\",\"nama_model\"]\n            )\n            if is_new or os.path.getsize(path) == 0:\n                w.writeheader()\n            w.writerow({\n                \"epoch\":       epoch_global,           # global (naik terus)\n                \"epoch_in_run\": epoch_in_run,         # 1..num_epochs per run\n                \"run_id\":     run_id,                 # penanda unik run\n                \"train_loss\": float(epoch_train_loss),\n                \"val_loss\":   float(epoch_val_loss),\n                \"val_psnr\":   float(epoch_psnr),\n                \"val_ssim\":   float(epoch_ssim),\n                \"nama_model\": ckpt_name               # hanya basename\n            })\n\n    print(\"Training Selesai.\")\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.188525Z","iopub.execute_input":"2025-11-12T06:01:36.188769Z","iopub.status.idle":"2025-11-12T06:01:36.205116Z","shell.execute_reply.started":"2025-11-12T06:01:36.188752Z","shell.execute_reply":"2025-11-12T06:01:36.204256Z"}},"outputs":[],"execution_count":22},{"id":"f81f5067-b961-441b-a14d-2cfd0b20dc6f","cell_type":"code","source":"class SuperResolutionDataset(Dataset):\n    \"\"\"\n    Dataset kustom untuk super-resolution.\n    Akan memuat gambar 256x256 (HR) dan secara otomatis\n    membuat versi 128x128 (LR) sebagai input.\n    \"\"\"\n    def __init__(self, image_folder):\n        self.root_dir = image_folder\n        # Dapatkan daftar semua nama file gambar di folder\n        self.image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n        \n        # Definisikan transform untuk HR (hanya konversi ke Tensor)\n        self.hr_transform = T.ToTensor()\n        \n        # Definisikan transform untuk LR (Resize ke 128x128 + konversi ke Tensor)\n        self.lr_transform = T.Compose([\n            T.Resize((128, 128), interpolation=T.InterpolationMode.BICUBIC),\n            T.ToTensor()\n        ])\n\n    def __len__(self):\n        # Mengembalikan jumlah total gambar\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        # 1. Dapatkan path lengkap ke satu gambar\n        img_path = os.path.join(self.root_dir, self.image_files[idx])\n        \n        # 2. Buka gambar HR (256x256) menggunakan PIL\n        #    Gunakan .convert('RGB') untuk memastikan gambar punya 3 channel\n        hr_image = Image.open(img_path).convert('RGB')\n        \n        # 3. Buat tensor HR dan LR dari gambar yang sama\n        lr_tensor = self.lr_transform(hr_image)\n        hr_tensor = self.hr_transform(hr_image)\n        \n        # 4. Kembalikan pasangan (input, target)\n        return lr_tensor, hr_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.205957Z","iopub.execute_input":"2025-11-12T06:01:36.206193Z","iopub.status.idle":"2025-11-12T06:01:36.220839Z","shell.execute_reply.started":"2025-11-12T06:01:36.206177Z","shell.execute_reply":"2025-11-12T06:01:36.220019Z"}},"outputs":[],"execution_count":23},{"id":"9b108d95","cell_type":"markdown","source":"## ARSITEKTUR","metadata":{}},{"id":"935b87a6","cell_type":"code","source":"class blocks (nn.Module):\n\n    def __init__(self, k_feature, N,H,W,C,j, head):\n        super().__init__()\n        self.j = j\n        self.N, self.C, self.H, self.W = N,C,H,W\n        self.k_feature = k_feature\n        self.head = head\n        self.dk = self.k_feature//self.head # dmodel = k_feature\n        self.n_win = self.H//self.j * self.W//self.j\n        self.rasio_ekspansi = 4\n    \n    # ============================ body Rir =====================================\n        # normalisasi\n        self.layernorm1 = nn.LayerNorm(normalized_shape=[self.k_feature])\n        self.layernorm2 = nn.LayerNorm(normalized_shape=[self.k_feature])\n\n        # Linear projections\n        self.wq = nn.Parameter(torch.empty(self.k_feature, self.k_feature))\n        self.wk = nn.Parameter(torch.empty(self.k_feature, self.k_feature))\n        self.wv = nn.Parameter(torch.empty(self.k_feature, self.k_feature))\n        self.wo = nn.Parameter(torch.empty(self.k_feature, self.k_feature))\n        self.bt = nn.Parameter(torch.zeros(self.head, self.j*self.j, self.j*self.j))\n\n        # MLP\n        self.w1 = nn.Parameter(torch.empty(self.k_feature, self.k_feature * self.rasio_ekspansi))\n        self.b1 = nn.Parameter(torch.zeros([self.k_feature*self.rasio_ekspansi]))\n        self.w2 = nn.Parameter(torch.empty(self.k_feature*self.rasio_ekspansi, self.k_feature))\n        self.b2 = nn.Parameter(torch.zeros([self.k_feature]))\n\n        # Panggil fungsi inisialisasi\n        self.init_weights()\n\n    def init_weights(self):\n        # === Xavier initialization untuk layer linear ===\n        nn.init.xavier_uniform_(self.wq)\n        nn.init.xavier_uniform_(self.wk)\n        nn.init.xavier_uniform_(self.wv)\n        nn.init.xavier_uniform_(self.wo)\n        nn.init.xavier_uniform_(self.w1)\n        nn.init.xavier_uniform_(self.w2)\n\n        # Bias nol sudah oke (default)\n        nn.init.zeros_(self.b1)\n        nn.init.zeros_(self.b2)\n\n        # Bisa juga He init jika ingin lebih cocok untuk ReLU:\n        # nn.init.kaiming_normal_(self.w1, nonlinearity='relu')\n        # nn.init.kaiming_normal_(self.w2, nonlinearity='relu')\n\n\n    def forward(self, x):\n\n        \n        # input kedala fungsi ini x [8,96,128,128]\n        \n        # =================================================--=======================================================\n        # ============================================== MSA =======================================================\n        # =================================================--=======================================================\n        \n        # menukra ukuran dimensi (N,C,H,W) => (N,H,W,C)\n        xp = x.permute(0,2,3,1)\n        \n        # normalisasi input\n       \n        xln1 = self.layernorm1(xp)\n        N_dyn, H_dyn, W_dyn, C_dyn = xln1.shape\n\n        # window partition. \n        # reshape (N,H,W,C) => ((N X n_win),j,j,k_feature)\n        # 1.view potong H dan W menjadi (numwin_H, j) dan (NumWin_W, j)\n        xr = xln1.view(N_dyn, H_dyn//self.j, self.j, W_dyn//self.j, self.j, C_dyn)\n        \n        # 2. permute [N, H//J, W//J, j,j, k_feature]\n        xwin = xr.permute(0,1,3,2,4,5).contiguous()\n\n        # 3.view gabugnkan semua jendela kedalam dimenci batch\n        # [N * num_wind * numwind , j,j, C]\n        xwin = xwin.view(-1,self.j,self.j,C_dyn)\n        # xr = xln1.reshape(self.N * self.n_win, self.j, self.j, self.k_feature)\n\n        # flatten ((N X n_win),j,j,C) => ((N X n_win),j*j,C)  \n        xf = xwin.reshape(-1, self.j * self.j, self.k_feature)\n\n        # self attention\n        # mencari Q,K,V\n        Q = xf @ self.wq\n        K = xf @ self.wk\n        V = xf @ self.wv\n\n        # split heads mengubah ukuran Q,K,V [2048,64,96] => menjadi [2048,64,6,16]\n        Q = Q.reshape((-1, self.j * self.j, self.head, self.k_feature//self.head))\n        K = K.reshape((-1, self.j * self.j, self.head, self.k_feature//self.head))\n        V = V.reshape((-1, self.j * self.j, self.head, self.k_feature//self.head))\n\n        # permute dari bentuk [2048,64,6,16] => [2048,6,64,16]\n        Q = Q.permute(0,2,1,3)\n        K = K.permute(0,2,1,3)\n        V = V.permute(0,2,1,3)\n\n        # SCALED dot product attention\n        score = Q.matmul(K.transpose(-2,-1))\n        scaling = score/(self.dk ** 0.5)\n        B = scaling + self.bt\n        P = F.softmax(B, dim=-1)\n        O = P @ V\n\n        #permute dari [2048,6,64,16] => [2048,64,6,16]\n        O = O.permute(0,2,1,3)\n        \n        #reshape menggabungkan head dari [2048,64,6,16] => [2048,64,96]\n        O = O.reshape(-1, self.j * self.j, self.k_feature )\n\n        # MSA_out\n        MSA_out = O @ self.wo\n\n        # mengubah kembali ke bentuk input awal [N,C,H,W]\n        # 1. Reshape ke [256, 8, 8, 96]\n        MSA_out = MSA_out.view(-1, self.j, self.j, self.k_feature) \n        \n        # 2. Reshape ke [N_dyn, NumWin_H, NumWin_W, j, j, C]\n        MSA_out = MSA_out.view(N_dyn, H_dyn // self.j, W_dyn // self.j, self.j, self.j, self.k_feature)\n        \n        # 3. Permute\n        MSA_out = MSA_out.permute(0, 1, 3, 2, 4, 5).contiguous()\n        \n        # 4. View ke [N_dyn, H_dyn, W_dyn, C]\n        MSA_out = MSA_out.view(N_dyn, H_dyn, W_dyn, self.k_feature)\n\n        # # reshape dari ukuran [2048,64,96] => [2048,8,8,96]\n        # MSA_out = MSA_out.reshape(self.N * self.n_win,self.j, self.j, self.k_feature)\n\n        # # reshape dari ukuran [2048,8,8,96] => [8,256,8,8,96]\n        # MSA_out = MSA_out.reshape(self.N, self.n_win, self.j, self.j, self.k_feature)\n\n        # # reshape dari ukuran [8,256,8,8,96] => [8,128,128,96]\n        # MSA_out = MSA_out.reshape(self.N, self.H, self.W, self.k_feature)\n\n        # permute untuk mengembalikan ke bentuk awal N,C,H,W\n        MSA_out = MSA_out.permute(0,-1,1,2)\n\n        #============ RESIDUAL =======================\n        xmsa = x + MSA_out # [N,k_feature, H,W] [8.96,128,128]\n\n        # =================================================--=======================================================\n        # ============================================== MLP =======================================================\n        # =================================================--=======================================================\n\n        # input x [N,k_feature, H,W] [8.96,128,128]\n        x2 = xmsa.clone()\n       # menukra ukuran dimensi (N,C,H,W) => (N,H,W,C)\n        xp = x2.permute(0,2,3,1)\n    \n        # normalisasi input\n        xln = self.layernorm2(xp)\n\n        # Multi Layer Perceptron \n        # layer1 (8,128,128,96) => (8,128,128,384)\n        x2 = xln @ self.w1 + self.b1\n        # aktivasi\n        x2 = F.gelu(x2)\n\n        # layer2 (8,128,128,384) => (8,128,128,96)\n        x2 = x2 @ self.w2 + self.b2\n\n        # permutasi\n        x2 = x2.permute(0,3,1,2)\n\n        # residual\n        x_out = x2 + xmsa\n        return x_out\n\nclass group(nn.Module):\n    def __init__(self, k_feature, N,H,W,C,j, head, j_blocks):\n        super().__init__()\n        self.j = j\n        self.N, self.C, self.H, self.W = N,C,H,W\n        self.k_feature = k_feature\n        self.head = head\n        self.dk = self.k_feature//self.head # dmodel = k_feature\n        self.n_win = self.H//self.j * self.W/self.j\n        \n        self.bloks = nn.ModuleList([\n            blocks(k_feature=self.k_feature, N=self.N,H=self.H,W=self.W,C=self.C,j=self.j, head = self.head) for _ in range(j_blocks)\n        ])\n\n    def forward(self, x):\n        xin = x.clone()\n        for blk in self.bloks:\n            x = blk(x)\n        # residual \\\n        x_out = xin + x\n        return x_out\n\n    \n\nclass RIR_interpolation(nn.Module):\n\n    def __init__(self, N,C,H,W,  k_feature, j_group, j_blocks):\n        super().__init__()\n        self.N, self.C, self.H, self.W = N,C,H,W\n        # self.groups = groups\n        self.blocks = j_blocks\n        self.j = 8  # ukuran window\n        self.k_feature = k_feature\n        self.head = 6\n        self.dk = self.k_feature//self.head # dmodel = k_feature\n        self.j_group = j_group\n        \n        self.n_win = self.H//self.j * self.W//self.j\n        \n        # [out_channels, in_channels, kernel, kernel]\n\n        # ========================== ekstraksi fitur ================================\n        self.w0 = nn.Parameter(torch.empty(self.k_feature, 3, 3, 3))\n        self.w1 = nn.Parameter(torch.empty(self.k_feature * 4, k_feature, 3, 3))\n        self.w2 = nn.Parameter(torch.empty(3, self.k_feature, 3, 3))\n        self.b0 = nn.Parameter(torch.zeros(self.k_feature))\n        self.b1 = nn.Parameter(torch.zeros(self.k_feature * 4))\n        self.b2 = nn.Parameter(torch.zeros(3))\n\n\n        # body \n        self.body = nn.ModuleList([\n            group(self.k_feature, self.N, self.H, self.W, self.C, self.j, self.head, 6) for _ in range(self.j_group)\n        ])\n        \n        \n        \n        self.pixshuffle = nn.PixelShuffle(upscale_factor=2)\n        self.init_weights()\n    \n\n    def init_weights(self):\n        # He initialization untuk convolution\n        nn.init.kaiming_normal_(self.w0, mode='fan_out', nonlinearity='relu')\n        nn.init.kaiming_normal_(self.w1, mode='fan_out', nonlinearity='relu')\n        nn.init.kaiming_normal_(self.w2, mode='fan_out', nonlinearity='relu')\n        nn.init.zeros_(self.b0)\n        nn.init.zeros_(self.b1)\n        nn.init.zeros_(self.b2)\n\n    \n        \n\n    def forward(self,x):\n\n        # =================Ekstraksi Fitur===========================\n        # input awal X [N,C,H,W] [8,3,128,128]\n        d = F.conv2d(x, self.w0, bias=self.b0, padding=1)\n        d = F.relu(d) # [8,96,128,128]\n        # output = X = [N,k_feature,H,W] [8,96,128,128]\n\n        \n        # ================== body rir ==============================\n        #  input awal X [N,k_featur,H,W] = [8,96,128,128]\n        \n        # b = self.body.forward(d)\n        din = d.clone()\n        for grp in self.body:\n            d = grp(d)\n\n        # residual\n        b = din + d\n            \n\n        # output sama dengan input X = X [N,k_featur,H,W] = [8,96,128,128]\n\n        \n        # =============== Upsampler/pixxel shuffle ==================\n        # input awal X [N,k_featur,H,W] = [8,96,128,128]\n        d = F.conv2d(b, self.w1, bias=self.b1, padding=1)\n        d = F.relu(d)\n        o = self.pixshuffle(d)\n\n        # Rekonstruksi\n        xsr = F.conv2d(o, self.w2, bias=self.b2, padding=1)\n        # output X [N.C,H*2,W*2]  [8,3,256,256]\n        \n        return xsr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.376562Z","iopub.execute_input":"2025-11-12T06:01:36.377079Z","iopub.status.idle":"2025-11-12T06:01:36.403075Z","shell.execute_reply.started":"2025-11-12T06:01:36.377052Z","shell.execute_reply":"2025-11-12T06:01:36.402242Z"}},"outputs":[],"execution_count":24},{"id":"5ca3804a","cell_type":"markdown","source":"## Load Model","metadata":{}},{"id":"de005367","cell_type":"code","source":"def load_model(model_architecture, path_hist):\n    \"\"\"\n    Memuat bobot (weights) yang tersimpan ke dalam arsitektur model.\n\n    Args:\n        model_architecture (nn.Module): Objek model yang arsitekturnya SAMA\n                                        (misal: Cnn_interpolation(k_feature=64)).\n        path_to_weights (str): Path ke file .pth yang disimpan.\n\n    Returns:\n        nn.Module: Model dengan bobot yang sudah dimuat.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # baca file csv\n    df = pd.read_csv(path_hist)\n    path_to_weights = \"/kaggle/working/model_checkpoints/\"+df['nama_model'].iloc[-1]\n    \n    \n    # Muat state_dict dari file\n    # map_location=device memastikan bobot dimuat ke device yang benar\n    state_dict = torch.load(path_to_weights, map_location=device)\n    \n    # Masukkan state_dict (bobot) ke dalam arsitektur model\n    model_architecture.load_state_dict(state_dict)\n    \n    # Pindahkan model ke device\n    model_architecture.to(device)\n    \n    # PENTING: Set model ke mode evaluasi/inferensi\n    # Ini menonaktifkan layer seperti Dropout atau BatchNorm (jika ada)\n    model_architecture.eval() \n    \n    print(f\"Model berhasil dimuat dari {path_to_weights}\")\n    return model_architecture","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.404785Z","iopub.execute_input":"2025-11-12T06:01:36.405610Z","iopub.status.idle":"2025-11-12T06:01:36.422658Z","shell.execute_reply.started":"2025-11-12T06:01:36.405585Z","shell.execute_reply":"2025-11-12T06:01:36.421885Z"}},"outputs":[],"execution_count":25},{"id":"12fbb90a","cell_type":"code","source":"import tkinter as tk\nfrom tkinter import filedialog\n\ndef pilih_file_weight():\n    \"\"\"\n    Membuka file explorer untuk memilih file .pth.\n    \"\"\"\n    root = tk.Tk()\n    root.withdraw()  # sembunyikan jendela utama Tkinter\n    file_path = filedialog.askopenfilename(\n        title=\"Pilih file weight (.pth)\",\n        filetypes=[(\"PyTorch model\", \"*.pth\"), (\"Semua file\", \"*.*\")]\n    )\n    return file_path\n\n\n# ==== Contoh penggunaan ====\n# Misalnya kamu sudah punya arsitektur model\n# model = Cnn_interpolation(k_feature=64)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.423481Z","iopub.execute_input":"2025-11-12T06:01:36.423728Z","iopub.status.idle":"2025-11-12T06:01:36.442100Z","shell.execute_reply.started":"2025-11-12T06:01:36.423709Z","shell.execute_reply":"2025-11-12T06:01:36.441248Z"}},"outputs":[],"execution_count":26},{"id":"fcfed6fe","cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"id":"9ddf3087","cell_type":"code","source":"import kagglehub\n\n# Download latest version\nPATH = kagglehub.dataset_download(\"mcparadip/anime-faces-waifu2x\")\n\n# # print(\"Path to dataset files:\", path)\n# PATH = \"/home/kanza/Dokumen/file/D2L/transformer/anim/archive\" # <-- GANTI INI\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.442916Z","iopub.execute_input":"2025-11-12T06:01:36.443253Z","iopub.status.idle":"2025-11-12T06:01:36.654265Z","shell.execute_reply.started":"2025-11-12T06:01:36.443226Z","shell.execute_reply":"2025-11-12T06:01:36.653304Z"}},"outputs":[],"execution_count":27},{"id":"b81d3452-5174-4f31-85bc-28797457fe24","cell_type":"markdown","source":"## Training","metadata":{}},{"id":"2eb036ef","cell_type":"markdown","source":"### Part","metadata":{}},{"id":"d65db65a","cell_type":"code","source":"# import torch\n# from torch.utils.data import DataLoader, Subset, random_split\n\n# # Tentukan path ke folder gambar Anda\n# PATH_KE_FOLDER_GAMBAR = PATH # <-- GANTI INI\n# BATCH_SIZE = 1\n# NUM_EPOCHS = 1\n# K_FEATURE = 96\n\n# # --- MODIFIKASI DIMULAI DI SINI ---\n\n# # 1. Buat dataset Lengkap\n# full_dataset = SuperResolutionDataset(image_folder=PATH_KE_FOLDER_GAMBAR)\n# print(f\"Ukuran dataset penuh: {len(full_dataset)}\")\n\n# # 2. Tentukan jumlah gambar yang ingin digunakan (misal, 100)\n# num_images_to_use = 2\n# indices = list(range(num_images_to_use))\n\n# # 3. Buat SUBSET dari dataset penuh\n# subset_dataset = Subset(full_dataset, indices)\n# print(f\"Ukuran subset yang akan digunakan: {len(subset_dataset)}\")\n\n# # 4. Tentukan ukuran split (sekarang berdasarkan subset_dataset)\n# train_size = int(0.8 * len(subset_dataset)) # Ini akan menjadi 80\n# val_size = len(subset_dataset) - train_size   # Ini akan menjadi 20\n\n# # 5. Lakukan split pada SUBSET tersebut\n# train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n\n# print(f\"Ukuran data training: {len(train_dataset)}\")\n# print(f\"Ukuran data validasi: {len(val_dataset)}\")\n\n# # --- MODIFIKASI SELESAI ---\n\n# # 6. Buat data loader train dan val (kode ini tetap sama)\n# train_loader = DataLoader(\n#     train_dataset, \n#     batch_size=BATCH_SIZE, \n#     shuffle=True, \n#     num_workers=4,\n#     pin_memory=True\n# )\n\n# val_loader = DataLoader(\n#     val_dataset,\n#     batch_size=BATCH_SIZE,\n#     shuffle=False, # Tidak perlu di-shuffle untuk validasi\n#     num_workers=4,\n#     pin_memory=True\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.656669Z","iopub.execute_input":"2025-11-12T06:01:36.656896Z","iopub.status.idle":"2025-11-12T06:01:36.676518Z","shell.execute_reply.started":"2025-11-12T06:01:36.656879Z","shell.execute_reply":"2025-11-12T06:01:36.675786Z"}},"outputs":[{"name":"stdout","text":"Ukuran dataset penuh: 21551\nUkuran subset yang akan digunakan: 2\nUkuran data training: 1\nUkuran data validasi: 1\n","output_type":"stream"}],"execution_count":28},{"id":"098adace","cell_type":"markdown","source":"### Full","metadata":{}},{"id":"381b8c2b","cell_type":"code","source":"# Tentukan path ke folder gambar Anda\nPATH_KE_FOLDER_GAMBAR = PATH # <-- GANTI INI\nBATCH_SIZE = 1\n\nK_FEATURE = 96\n\n# 1. Buat dataset Lengkap\nfull_dataset =  SuperResolutionDataset(image_folder=PATH_KE_FOLDER_GAMBAR)\nprint(len(full_dataset))\n\n# 2. Tentukan ukuran split \ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\n\n# 3.Lakukan split\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\nprint(f\"Ukuran data training: {len(train_dataset)}\")\nprint(f\"Ukuran data validasi: {len(val_dataset)}\")\n\n# 4. buat data loader train dan val\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=True, \n    num_workers=1,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False, # Tidak perlu di-shuffle untuk validasi\n    num_workers=1,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:09:06.978907Z","iopub.execute_input":"2025-11-12T06:09:06.979267Z","iopub.status.idle":"2025-11-12T06:09:06.999693Z","shell.execute_reply.started":"2025-11-12T06:09:06.979241Z","shell.execute_reply":"2025-11-12T06:09:06.998781Z"}},"outputs":[{"name":"stdout","text":"21551\nUkuran data training: 17240\nUkuran data validasi: 4311\n","output_type":"stream"}],"execution_count":40},{"id":"b39cd076","cell_type":"markdown","source":"## Training","metadata":{}},{"id":"8544557e","cell_type":"code","source":"NUM_EPOCHS = 1\n# ================================================== inisialisasi model ==========================================\nmodel = RIR_interpolation(\n    N=1,\n    C=3,\n    H=128,\n    W=128,\n    k_feature=96,\n    j_group=6,\n    j_blocks=6)\n\nmodel = model.to(device)           # ⬅️ pindahkan SEMUA parameter model ke GPU\n\n# tentukan loss function\ncriterion = nn.L1Loss()\n\n# menentukan optimizer \noptimizer = optim.Adam(model.parameters(),lr=0.0001)\n\n\n# ================================= Trainig ===================================================================\n# 6. Mulai Training dan TANGKAP output history\nhistory = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,  # Berikan val_loader di sini\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=NUM_EPOCHS,\n    save_dir=\"model_checkpoints\",\n    continue_global_epoch=False\n)\n\n# 7. Tampilkan hasil history\nprint(\"\\n--- Hasil History Training ---\")\nimport json\nprint(json.dumps(history, indent=2))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:36.682947Z","iopub.execute_input":"2025-11-12T06:01:36.683270Z","iopub.status.idle":"2025-11-12T06:01:52.239073Z","shell.execute_reply.started":"2025-11-12T06:01:36.683241Z","shell.execute_reply":"2025-11-12T06:01:52.237817Z"}},"outputs":[{"name":"stdout","text":"Mulai Training di device: cpu | run_id=2025-11-12_06-01-36 | start_epoch_global=0\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/1 [Train]: 100%|██████████| 1/1 [00:10<00:00, 10.92s/it, train_loss=318]\nEpoch 1/1 [Val]: 100%|██████████| 1/1 [00:04<00:00,  4.48s/it, val_loss=203]","output_type":"stream"},{"name":"stdout","text":"[SAVE] model_checkpoints/model_2025-11-12_06-01-36_e1.pth\nTraining Selesai.\n\n--- Hasil History Training ---\n{\n  \"train_loss\": [\n    317.6674499511719\n  ],\n  \"val_loss\": [\n    202.7695770263672\n  ],\n  \"val_psnr\": [\n    -48.29279327392578\n  ],\n  \"val_ssim\": [\n    -1.750330511640641e-07\n  ]\n}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"id":"1d46af59-26cb-4d06-8b23-16eba16a8af4","cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/working/histor.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:01:52.240327Z","iopub.execute_input":"2025-11-12T06:01:52.240711Z","iopub.status.idle":"2025-11-12T06:01:52.275592Z","shell.execute_reply.started":"2025-11-12T06:01:52.240672Z","shell.execute_reply":"2025-11-12T06:01:52.274781Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   epoch  epoch_in_run               run_id  train_loss    val_loss  \\\n0      1             1  2025-11-12_06-01-36   317.66745  202.769577   \n\n    val_psnr      val_ssim                        nama_model  \n0 -48.292793 -1.750331e-07  model_2025-11-12_06-01-36_e1.pth  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>epoch_in_run</th>\n      <th>run_id</th>\n      <th>train_loss</th>\n      <th>val_loss</th>\n      <th>val_psnr</th>\n      <th>val_ssim</th>\n      <th>nama_model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2025-11-12_06-01-36</td>\n      <td>317.66745</td>\n      <td>202.769577</td>\n      <td>-48.292793</td>\n      <td>-1.750331e-07</td>\n      <td>model_2025-11-12_06-01-36_e1.pth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"id":"990d1611","cell_type":"markdown","source":"## Fine Tuning","metadata":{}},{"id":"c65b6e95","cell_type":"code","source":"# model = RIR_interpolation(\n#     N=1,\n#     C=3,\n#     H=128,\n#     W=128,\n#     k_feature=96,\n#     j_group=6,\n#     j_blocks=6)\n\n\n# load_model(model, '/kaggle/working/histor.csv')\n\n# model = model.to(device)           # ⬅️ pindahkan SEMUA parameter model ke GPU\n\n# # tentukan loss function\n# criterion = nn.L1Loss()\n\n# # menentukan optimizer \n# optimizer = optim.Adam(model.parameters(),lr=0.0001)\n\n\n# # ================================= Trainig ===================================================================\n# # 6. Mulai Training dan TANGKAP output history\n# history = train_model(\n#     model=model,\n#     train_loader=train_loader,\n#     val_loader=val_loader,  # Berikan val_loader di sini\n#     criterion=criterion,\n#     optimizer=optimizer,\n#     num_epochs=3,\n#     save_dir=\"model_checkpoints\",\n#     continue_global_epoch=True\n# )\n\n# # 7. Tampilkan hasil history\n# print(\"\\n--- Hasil History Training ---\")\n# import json\n# print(json.dumps(history, indent=2))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:04:42.208048Z","iopub.execute_input":"2025-11-12T06:04:42.208368Z","iopub.status.idle":"2025-11-12T06:06:07.095445Z","shell.execute_reply.started":"2025-11-12T06:04:42.208297Z","shell.execute_reply":"2025-11-12T06:06:07.093555Z"}},"outputs":[{"name":"stdout","text":"Model berhasil dimuat dari /kaggle/working/model_checkpoints/model_2025-11-12_06-01-36_e1.pth\nMulai Training di device: cpu | run_id=2025-11-12_06-04-42 | start_epoch_global=1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3 [Train]: 100%|██████████| 1/1 [00:16<00:00, 16.02s/it, train_loss=213]\nEpoch 1/3 [Val]: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it, val_loss=155]\n","output_type":"stream"},{"name":"stdout","text":"[SAVE] model_checkpoints/model_2025-11-12_06-04-42_e1.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Train]: 100%|██████████| 1/1 [00:34<00:00, 34.47s/it, train_loss=165]\nEpoch 2/3 [Val]: 100%|██████████| 1/1 [00:04<00:00,  4.94s/it, val_loss=154]\n","output_type":"stream"},{"name":"stdout","text":"[SAVE] model_checkpoints/model_2025-11-12_06-04-42_e2.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3 [Train]: 100%|██████████| 1/1 [00:21<00:00, 21.13s/it, train_loss=149]\nEpoch 3/3 [Val]: 100%|██████████| 1/1 [00:03<00:00,  3.94s/it, val_loss=154]","output_type":"stream"},{"name":"stdout","text":"[SAVE] model_checkpoints/model_2025-11-12_06-04-42_e3.pth\nTraining Selesai.\n\n--- Hasil History Training ---\n{\n  \"train_loss\": [\n    213.0382080078125,\n    165.12892150878906,\n    149.1511993408203\n  ],\n  \"val_loss\": [\n    154.54554748535156,\n    154.03724670410156,\n    153.84164428710938\n  ],\n  \"val_psnr\": [\n    -45.33511734008789,\n    -45.496482849121094,\n    -46.31485366821289\n  ],\n  \"val_ssim\": [\n    -2.410760373550147e-07,\n    -1.7129550542449579e-06,\n    -1.9025256960958359e-06\n  ]\n}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":36},{"id":"43b70841-eb51-4cac-9d35-f75b9c7e40b2","cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/working/histor.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T06:06:12.582377Z","iopub.execute_input":"2025-11-12T06:06:12.582748Z","iopub.status.idle":"2025-11-12T06:06:12.611030Z","shell.execute_reply.started":"2025-11-12T06:06:12.582714Z","shell.execute_reply":"2025-11-12T06:06:12.609996Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   epoch  epoch_in_run               run_id  train_loss    val_loss  \\\n0      1             1  2025-11-12_06-01-36  317.667450  202.769577   \n1      2             1  2025-11-12_06-04-42  213.038208  154.545547   \n2      3             2  2025-11-12_06-04-42  165.128922  154.037247   \n3      4             3  2025-11-12_06-04-42  149.151199  153.841644   \n\n    val_psnr      val_ssim                        nama_model  \n0 -48.292793 -1.750331e-07  model_2025-11-12_06-01-36_e1.pth  \n1 -45.335117 -2.410760e-07  model_2025-11-12_06-04-42_e1.pth  \n2 -45.496483 -1.712955e-06  model_2025-11-12_06-04-42_e2.pth  \n3 -46.314854 -1.902526e-06  model_2025-11-12_06-04-42_e3.pth  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>epoch_in_run</th>\n      <th>run_id</th>\n      <th>train_loss</th>\n      <th>val_loss</th>\n      <th>val_psnr</th>\n      <th>val_ssim</th>\n      <th>nama_model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2025-11-12_06-01-36</td>\n      <td>317.667450</td>\n      <td>202.769577</td>\n      <td>-48.292793</td>\n      <td>-1.750331e-07</td>\n      <td>model_2025-11-12_06-01-36_e1.pth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2025-11-12_06-04-42</td>\n      <td>213.038208</td>\n      <td>154.545547</td>\n      <td>-45.335117</td>\n      <td>-2.410760e-07</td>\n      <td>model_2025-11-12_06-04-42_e1.pth</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>2025-11-12_06-04-42</td>\n      <td>165.128922</td>\n      <td>154.037247</td>\n      <td>-45.496483</td>\n      <td>-1.712955e-06</td>\n      <td>model_2025-11-12_06-04-42_e2.pth</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3</td>\n      <td>2025-11-12_06-04-42</td>\n      <td>149.151199</td>\n      <td>153.841644</td>\n      <td>-46.314854</td>\n      <td>-1.902526e-06</td>\n      <td>model_2025-11-12_06-04-42_e3.pth</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"id":"1a8774e2-215e-4a88-ab9b-8d032f936b5f","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}